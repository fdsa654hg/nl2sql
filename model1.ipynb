{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "placed-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "from utils import read_data, read_tables, SQL, Query, Question, Table\n",
    "\n",
    "from opencc import OpenCC\n",
    "cc = OpenCC('s2twp')\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "static-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table_file = './data/train/train.tables.json'\n",
    "train_data_file = './data/train/train.json'\n",
    "\n",
    "val_table_file = './data/val/val.tables.json'\n",
    "val_data_file = './data/val/val.json'\n",
    "\n",
    "test_table_file = './data/test/test.tables.json'\n",
    "test_data_file = './data/test/test.json'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-bert-wwm\")\n",
    "model = BertModel.from_pretrained(\"hfl/chinese-bert-wwm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "polish-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tables = read_tables(train_table_file)\n",
    "train_data, train_max_len, train_max_header_len = read_data(train_data_file, train_tables)\n",
    "\n",
    "val_tables = read_tables(val_table_file)\n",
    "val_data, val_max_len, val_max_header_len = read_data(val_data_file, val_tables)\n",
    "\n",
    "test_tables = read_tables(test_table_file)\n",
    "test_data = read_data(test_data_file, test_tables)\n",
    "\n",
    "max_len = max(train_max_len, val_max_len)\n",
    "max_header_len = max(train_max_header_len, val_max_header_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "related-custody",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len, max_header_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "durable-therapist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41522, 4396, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "choice-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_brackets(s):\n",
    "    '''\n",
    "    Remove [] ()\n",
    "    '''\n",
    "    return re.sub(r'[\\(\\（].*[\\)\\）]', '', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "excited-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryTokenizer:\n",
    "    \n",
    "    def __init__(self, tokenizer,col_orders=None):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.col_type_token_dict = {'text': '[unused11]', 'real': '[unused12]'}\n",
    "    \n",
    "    def tokenize(self, query: Query, col_orders=None):\n",
    "\n",
    "        question_tokens = ['[CLS]'] + self.tokenizer.tokenize(cc.convert(query.question.text))\n",
    "        header_tokens = []\n",
    "        \n",
    "        if col_orders is None:\n",
    "            col_orders = np.arange(len(query.table.header))\n",
    "        \n",
    "        header = [query.table.header[i] for i in col_orders]\n",
    "        \n",
    "        for col_name, col_type in header:\n",
    "            col_type_token = self.col_type_token_dict[col_type]\n",
    "            col_name = cc.convert(remove_brackets(col_name))\n",
    "            col_name_tokens = self.tokenizer.tokenize(col_name)\n",
    "            col_tokens = [col_type_token] + col_name_tokens\n",
    "            header_tokens.append(col_tokens)\n",
    "            \n",
    "        all_tokens = [question_tokens] + header_tokens\n",
    "        return self.pack(*all_tokens)\n",
    "    \n",
    "    def encode(self, query:Query, col_orders=None):\n",
    "        tokens, tokens_lens = self.tokenize(query, col_orders)\n",
    "#         token_ids = F.pad(torch.tensor(self.tokenizer.encode(tokens)[1:-1]), (0, max_len - len(tokens)))\n",
    "        token_ids = torch.as_tensor(self.tokenizer.encode(tokens)[1:-1])\n",
    "        segment_ids = [0] * len(token_ids)\n",
    "        attention_mask = [1] * len(token_ids)\n",
    "        header_indices = np.cumsum(tokens_lens)\n",
    "#         header_indices = F.pad(torch.tensor(header_indices[:-1]), (0, max_header_len - len(header_indices[:-1])))\n",
    "        header_indices = torch.as_tensor(header_indices[:-1])\n",
    "        return token_ids, attention_mask, segment_ids, header_indices\n",
    "    \n",
    "    def pack(self, *tokens_list):\n",
    "        packed_tokens_list = []\n",
    "        packed_tokens_lens = []\n",
    "        for tokens in tokens_list:\n",
    "            packed_tokens_list += tokens + ['[SEP]']\n",
    "            packed_tokens_lens.append(len(tokens) + 1)\n",
    "        return packed_tokens_list, packed_tokens_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "spectacular-session",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[PAD]']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tokenizer = QueryTokenizer(tokenizer)\n",
    "sample_query = train_data[0]\n",
    "tokenizer.convert_ids_to_tokens(['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "expired-diploma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QueryTokenizer\n",
      "\n",
      "Input Question:\n",
      "二零一九年第四周大黃蜂和密室逃生這兩部影片的票房總佔比是多少呀\n",
      "\n",
      "Input Header:\n",
      "影片名稱(text) | 周票房（萬）(real) | 票房佔比（%）(real) | 場均人次(real)\n",
      "\n",
      "Output Tokens:\n",
      "[CLS] 二 零 一 九 年 第 四 周 大 黃 蜂 和 密 室 逃 生 這 兩 部 影 片 的 票 房 總 佔 比 是 多 少 呀 [SEP] [unused11] 影 片 名 稱 [SEP] [unused12] 周 票 房 [SEP] [unused12] 票 房 佔 比 [SEP] [unused12] 場 均 人 次 [SEP]\n",
      "\n",
      "Output token_ids:\n",
      "tensor([ 101,  753, 7439,  671,  736, 2399, 5018, 1724, 1453, 1920, 7941, 6044,\n",
      "        1469, 2166, 2147, 6845, 4495, 6857, 1060, 6956, 2512, 4275, 4638, 4873,\n",
      "        2791, 5244,  861, 3683, 3221, 1914, 2208, 1435,  102,   11, 2512, 4275,\n",
      "        1399, 4935,  102,   12, 1453, 4873, 2791,  102,   12, 4873, 2791,  861,\n",
      "        3683,  102,   12, 1842, 1772,  782, 3613,  102])\n",
      "Output attention_mask:\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Output segment_ids:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Output header_ids:\n",
      "tensor([33, 39, 44, 50])\n"
     ]
    }
   ],
   "source": [
    "print('QueryTokenizer\\n')\n",
    "print('Input Question:\\n{}\\n'.format(sample_query.question))\n",
    "print('Input Header:\\n{}\\n'.format(sample_query.table.header))\n",
    "print('Output Tokens:\\n{}\\n'.format(' '.join(query_tokenizer.tokenize(sample_query)[0])))\n",
    "print('Output token_ids:\\n{}\\nOutput attention_mask:\\n{}\\nOutput segment_ids:\\n{}\\nOutput header_ids:\\n{}'\n",
    "      .format(*query_tokenizer.encode(sample_query)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "historic-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqlLabelEncoder:\n",
    "    \"\"\"\n",
    "    Convert SQL object into training labels.\n",
    "    \"\"\"\n",
    "    def encode(self, sql: SQL, num_cols):\n",
    "        cond_conn_op_label = sql.cond_conn_op\n",
    "        \n",
    "        sel_agg_label = np.ones(num_cols, dtype='int32') * len(SQL.agg_sql_dict)\n",
    "        for col_id, agg_op in zip(sql.sel, sql.agg):\n",
    "            if col_id < num_cols:\n",
    "                sel_agg_label[col_id] = agg_op\n",
    "            \n",
    "        cond_op_label = np.ones(num_cols, dtype='int32') * len(SQL.op_sql_dict)\n",
    "        for col_id, cond_op, _ in sql.conds:\n",
    "            if col_id < num_cols:\n",
    "                cond_op_label[col_id] = cond_op\n",
    "            \n",
    "        return cond_conn_op_label, sel_agg_label, cond_op_label\n",
    "    \n",
    "    def decode(self, cond_conn_op_label, sel_agg_label, cond_op_label):\n",
    "        cond_conn_op = int(cond_conn_op_label)\n",
    "        sel, agg, conds = [], [], []\n",
    "\n",
    "        for col_id, (agg_op, cond_op) in enumerate(zip(sel_agg_label, cond_op_label)):\n",
    "            if agg_op < len(SQL.agg_sql_dict):\n",
    "                sel.append(col_id)\n",
    "                agg.append(int(agg_op))\n",
    "            if cond_op < len(SQL.op_sql_dict):\n",
    "                conds.append([col_id, int(cond_op)])\n",
    "        return {\n",
    "            'sel': sel,\n",
    "            'agg': agg,\n",
    "            'cond_conn_op': cond_conn_op,\n",
    "            'conds': conds\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "funny-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = SqlLabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "naughty-tanzania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cond_conn_op': 2,\n",
       " 'sel': [2],\n",
       " 'agg': [5],\n",
       " 'conds': [[0, 2, '大黄蜂'], [0, 2, '密室逃生']]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(sample_query.sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "attached-cinema",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, array([6, 6, 5, 6], dtype=int32), array([2, 4, 4, 4], dtype=int32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.encode(sample_query.sql, num_cols=len(sample_query.table.header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "particular-professor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sel': [2], 'agg': [5], 'cond_conn_op': 2, 'conds': [[0, 2]]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.decode(*label_encoder.encode(sample_query.sql, num_cols=len(sample_query.table.header)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "demanding-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 data, \n",
    "                 tokenizer, \n",
    "                 label_encoder,\n",
    "                 is_train=True,\n",
    "                ):\n",
    "        \n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_encoder = label_encoder\n",
    "        self._global_indices = np.arange(len(data))\n",
    "        self.is_train = is_train\n",
    "\n",
    "            \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        query = self.data[index]\n",
    "        question = query.question.text\n",
    "        table = query.table\n",
    "            \n",
    "        col_orders = np.arange(len(table.header))\n",
    "            \n",
    "        token_ids, attention_mask, segment_ids, header_ids = self.tokenizer.encode(query, col_orders)\n",
    "        header_ids = [hid for hid in header_ids]\n",
    "        \n",
    "        count = 0\n",
    "        for i in header_ids:\n",
    "            l = int(i)\n",
    "            if not l == 0:\n",
    "                count+=1\n",
    "                \n",
    "        header_mask = [1] * count\n",
    "        col_orders = col_orders[: len(header_ids)]\n",
    "         \n",
    "        \n",
    "        inputs = {\n",
    "            'input_token_ids': torch.as_tensor(token_ids),\n",
    "            'input_attention_mask': torch.as_tensor(attention_mask),\n",
    "            'input_segment_ids': torch.as_tensor(segment_ids),\n",
    "            'input_header_ids': torch.as_tensor(header_ids),\n",
    "            'input_header_mask': F.pad(torch.tensor(header_mask), (0, len(header_ids) - len(header_mask))),\n",
    "        }\n",
    "        if self.is_train:\n",
    "            true_sql = self.label_encoder.decode(*self.label_encoder.encode(query.sql, num_cols=len(query.table.header)))\n",
    "            sql = query.sql\n",
    "            \n",
    "            cond_conn_op, sel_agg, cond_op = self.label_encoder.encode(sql, num_cols=len(table.header))\n",
    "            \n",
    "            sel_agg = sel_agg[col_orders]\n",
    "            cond_op = cond_op[col_orders]\n",
    "\n",
    "            outputs = {\n",
    "                'output_sel_agg':  torch.as_tensor(sel_agg),\n",
    "                'output_cond_conn_op': torch.tensor(cond_conn_op),\n",
    "                'output_cond_op': torch.tensor(cond_op),\n",
    "            }\n",
    "            return inputs, outputs, true_sql\n",
    "        else:\n",
    "            return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accessory-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = SQLDataset(train_data, query_tokenizer, label_encoder)\n",
    "val_set = SQLDataset(val_data, query_tokenizer, label_encoder)\n",
    "test_set = SQLDataset(test_data[0], query_tokenizer, label_encoder, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prostate-bullet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_token_ids': tensor([ 101,  753, 7439,  671,  736, 2399, 5018, 1724, 1453, 1920, 7941, 6044,\n",
      "        1469, 2166, 2147, 6845, 4495, 6857, 1060, 6956, 2512, 4275, 4638, 4873,\n",
      "        2791, 5244,  861, 3683, 3221, 1914, 2208, 1435,  102,   11, 2512, 4275,\n",
      "        1399, 4935,  102,   12, 1453, 4873, 2791,  102,   12, 4873, 2791,  861,\n",
      "        3683,  102,   12, 1842, 1772,  782, 3613,  102]), 'input_attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1]), 'input_segment_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'input_header_ids': tensor([33, 39, 44, 50]), 'input_header_mask': tensor([1, 1, 1, 1])}, {'output_sel_agg': tensor([6, 6, 5, 6], dtype=torch.int32), 'output_cond_conn_op': tensor(2), 'output_cond_op': tensor([2, 4, 4, 4], dtype=torch.int32)}, {'sel': [2], 'agg': [5], 'cond_conn_op': 2, 'conds': [[0, 2]]})\n",
      "({'input_token_ids': tensor([ 101,  872, 1962, 8024,  872, 4761, 6887,  791, 2399, 5018, 1724, 1453,\n",
      "        2166, 2147, 6845, 4495, 8024, 6917, 3300, 6929, 6956, 1920, 7941, 6044,\n",
      "        2124,  947, 4873, 2791, 5244, 4638,  861, 3683, 1621,  102,   11, 2512,\n",
      "        4275, 1399, 4935,  102,   12, 1453, 4873, 2791,  102,   12, 4873, 2791,\n",
      "         861, 3683,  102,   12, 1842, 1772,  782, 3613,  102]), 'input_attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1]), 'input_segment_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0]), 'input_header_ids': tensor([34, 40, 45, 51]), 'input_header_mask': tensor([1, 1, 1, 1])}, {'output_sel_agg': tensor([6, 6, 5, 6], dtype=torch.int32), 'output_cond_conn_op': tensor(2), 'output_cond_op': tensor([2, 4, 4, 4], dtype=torch.int32)}, {'sel': [2], 'agg': [5], 'cond_conn_op': 2, 'conds': [[0, 2]]})\n"
     ]
    }
   ],
   "source": [
    "print(train_set[0])\n",
    "print(train_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "little-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence,  pad_sequence\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_token_ids = []\n",
    "    input_attention_mask = []\n",
    "    input_segment_ids = []\n",
    "    input_header_ids = []\n",
    "    input_header_mask = []\n",
    "    output_sel_agg = []\n",
    "    output_cond_conn_op = []\n",
    "    output_cond_op = []\n",
    "    true_sqls = []\n",
    "    \n",
    "    for d in batch:\n",
    "        input_token_ids.append(d[0]['input_token_ids'])\n",
    "        input_attention_mask.append(d[0]['input_attention_mask'])\n",
    "        input_segment_ids.append(d[0]['input_segment_ids'])\n",
    "        input_header_ids.append(d[0]['input_header_ids'])\n",
    "        input_header_mask.append(d[0]['input_header_mask'])\n",
    "        output_sel_agg.append(d[1]['output_sel_agg'])\n",
    "        output_cond_conn_op.append(d[1]['output_cond_conn_op'])\n",
    "        output_cond_op.append(d[1]['output_cond_op'])\n",
    "        true_sqls.append(d[2])\n",
    "        \n",
    "    input_token_ids_len = torch.tensor([l.numel() for l in input_token_ids])\n",
    "    input_header_ids_len = torch.tensor([l.numel() for l in input_header_ids])\n",
    "    \n",
    "    padded_input_token_ids_batch = pad_sequence(input_token_ids, batch_first=True)\n",
    "    padded_input_attention_mask_batch = pad_sequence(input_attention_mask, batch_first=True)\n",
    "    padded_input_segment_ids_batch = pad_sequence(input_segment_ids, batch_first=True)\n",
    "    padded_input_header_ids_batch = pad_sequence(input_header_ids, batch_first=True)\n",
    "    padded_input_header_mask_batch = pad_sequence(input_header_mask, batch_first=True)\n",
    "    padded_output_sel_agg_batch = pad_sequence(output_sel_agg, batch_first=True, padding_value=-1)\n",
    "    padded_output_cond_conn_op_batch = torch.tensor(output_cond_conn_op).unsqueeze(-1)\n",
    "    padded_output_cond_op_batch = pad_sequence(output_cond_op, batch_first=True, padding_value=-1)\n",
    "\n",
    "    out1 = dict()\n",
    "    out2 = dict()\n",
    "    \n",
    "    out1['input_token_ids'] = padded_input_token_ids_batch\n",
    "    out1['input_attention_mask'] = padded_input_attention_mask_batch\n",
    "    out1['input_segment_ids'] = padded_input_segment_ids_batch\n",
    "    out1['input_header_ids'] = padded_input_header_ids_batch\n",
    "    out1['input_header_mask'] = padded_input_header_mask_batch\n",
    "    out2['output_sel_agg'] = padded_output_sel_agg_batch\n",
    "    out2['output_cond_conn_op'] = padded_output_cond_conn_op_batch\n",
    "    out2['output_cond_op'] = padded_output_cond_op_batch\n",
    "    \n",
    "    return (out1, out2), input_token_ids_len, input_header_ids_len, true_sqls\n",
    "\n",
    "def collate_fn2(batch):\n",
    "    input_token_ids = []\n",
    "    input_attention_mask = []\n",
    "    input_segment_ids = []\n",
    "    input_header_ids = []\n",
    "    input_header_mask = []\n",
    "    \n",
    "    for d in batch:\n",
    "        input_token_ids.append(d['input_token_ids'])\n",
    "        input_attention_mask.append(d['input_attention_mask'])\n",
    "        input_segment_ids.append(d['input_segment_ids'])\n",
    "        input_header_ids.append(d['input_header_ids'])\n",
    "        input_header_mask.append(d['input_header_mask'])\n",
    "        \n",
    "    input_token_ids_len = torch.tensor([l.numel() for l in input_token_ids])\n",
    "    input_header_ids_len = torch.tensor([l.numel() for l in input_header_ids])\n",
    "    \n",
    "    padded_input_token_ids_batch = pad_sequence(input_token_ids, batch_first=True)\n",
    "    padded_input_attention_mask_batch = pad_sequence(input_attention_mask, batch_first=True)\n",
    "    padded_input_segment_ids_batch = pad_sequence(input_segment_ids, batch_first=True)\n",
    "    padded_input_header_ids_batch = pad_sequence(input_header_ids, batch_first=True)\n",
    "    padded_input_header_mask_batch = pad_sequence(input_header_mask, batch_first=True)\n",
    "\n",
    "    out1 = dict()\n",
    "    \n",
    "    out1['input_token_ids'] = padded_input_token_ids_batch\n",
    "    out1['input_attention_mask'] = padded_input_attention_mask_batch\n",
    "    out1['input_segment_ids'] = padded_input_segment_ids_batch\n",
    "    out1['input_header_ids'] = padded_input_header_ids_batch\n",
    "    out1['input_header_mask'] = padded_input_header_mask_batch\n",
    "    \n",
    "    return (out1), input_token_ids_len, input_header_ids_len, true_sqls\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_set, batch_size=batch_size, collate_fn=collate_fn, shuffle=True, num_workers=10)\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_set, batch_size=batch_size, collate_fn=collate_fn, shuffle=False, num_workers=10)\n",
    "\n",
    "# a, b , c= train_loader.__iter__().__next__()\n",
    "# print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "toxic-salvation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 5 3\n",
      "{0: '', 1: 'AVG', 2: 'MAX', 3: 'MIN', 4: 'COUNT', 5: 'SUM'} {0: '>', 1: '<', 2: '==', 3: '!='} {0: '', 1: 'and', 2: 'or'}\n"
     ]
    }
   ],
   "source": [
    "# output sizes\n",
    "num_sel_agg = len(SQL.agg_sql_dict) + 1\n",
    "num_cond_op = len(SQL.op_sql_dict) + 1\n",
    "num_cond_conn_op = len(SQL.conn_sql_dict)\n",
    "\n",
    "print(num_sel_agg, num_cond_op, num_cond_conn_op)\n",
    "print(SQL.agg_sql_dict, SQL.op_sql_dict, SQL.conn_sql_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ongoing-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "def seq_gather(x):\n",
    "    seq, idxs = x\n",
    "    idxs = torch.as_tensor(idxs).type(torch.int64)\n",
    "    offset = torch.arange(0, seq.size(0) * seq.size(1), seq.size(1)).to(device)\n",
    "    idxs = idxs + offset.unsqueeze(1)\n",
    "\n",
    "    seq = seq.reshape(-1, seq.shape[-1])[idxs]\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "heated-friendly",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "received-difficulty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 199 different named parameters.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "selected-government",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Embedding Layer ====\n",
      "\n",
      "embeddings.word_embeddings.weight                       (21128, 768)\n",
      "embeddings.position_embeddings.weight                     (512, 768)\n",
      "embeddings.token_type_embeddings.weight                     (2, 768)\n",
      "embeddings.LayerNorm.weight                                   (768,)\n",
      "embeddings.LayerNorm.bias                                     (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "encoder.layer.0.attention.self.query.weight               (768, 768)\n",
      "encoder.layer.0.attention.self.query.bias                     (768,)\n",
      "encoder.layer.0.attention.self.key.weight                 (768, 768)\n",
      "encoder.layer.0.attention.self.key.bias                       (768,)\n",
      "encoder.layer.0.attention.self.value.weight               (768, 768)\n",
      "encoder.layer.0.attention.self.value.bias                     (768,)\n",
      "encoder.layer.0.attention.output.dense.weight             (768, 768)\n",
      "encoder.layer.0.attention.output.dense.bias                   (768,)\n",
      "encoder.layer.0.attention.output.LayerNorm.weight             (768,)\n",
      "encoder.layer.0.attention.output.LayerNorm.bias               (768,)\n",
      "encoder.layer.0.intermediate.dense.weight                (3072, 768)\n",
      "encoder.layer.0.intermediate.dense.bias                      (3072,)\n",
      "encoder.layer.0.output.dense.weight                      (768, 3072)\n",
      "encoder.layer.0.output.dense.bias                             (768,)\n",
      "encoder.layer.0.output.LayerNorm.weight                       (768,)\n",
      "encoder.layer.0.output.LayerNorm.bias                         (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "encoder.layer.11.output.LayerNorm.weight                      (768,)\n",
      "encoder.layer.11.output.LayerNorm.bias                        (768,)\n",
      "pooler.dense.weight                                       (768, 768)\n",
      "pooler.dense.bias                                             (768,)\n"
     ]
    }
   ],
   "source": [
    "print('==== Embedding Layer ====\\n')\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "suited-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _viterbi_decode(self, feats):\n",
    "        '''\n",
    "        Max-Product Algorithm or viterbi algorithm, argmax(p(z_0:t|x_0:t))\n",
    "        '''\n",
    "        \n",
    "        # T = self.max_seq_length\n",
    "        T = feats.shape[1]\n",
    "        batch_size = feats.shape[0]\n",
    "\n",
    "        # batch_transitions=self.transitions.expand(batch_size,self.tagset_size,self.tagset_size)\n",
    "\n",
    "        log_delta = torch.Tensor(batch_size, 1, self.tagset_size).fill_(-10000.).to(self.device)\n",
    "        log_delta[:, 0, self.start_label_id] = 0.\n",
    "        \n",
    "        # psi is for the vaule of the last latent that make P(this_latent) maximum.\n",
    "        psi = torch.zeros((batch_size, T, self.tagset_size), dtype=torch.long)  # psi[0]=0000 useless\n",
    "        for t in range(1, T):\n",
    "            # delta[t][k]=max_z1:t-1( p(x1,x2,...,xt,z1,z2,...,zt-1,zt=k|theta) )\n",
    "            # delta[t] is the max prob of the path from  z_t-1 to z_t[k]\n",
    "            log_delta, psi[:, t] = torch.max(self.transitions + log_delta, -1)\n",
    "            # psi[t][k]=argmax_z1:t-1( p(x1,x2,...,xt,z1,z2,...,zt-1,zt=k|theta) )\n",
    "            # psi[t][k] is the path choosed from z_t-1 to z_t[k],the value is the z_state(is k) index of z_t-1\n",
    "            log_delta = (log_delta + feats[:, t]).unsqueeze(1)\n",
    "\n",
    "        # trace back\n",
    "        path = torch.zeros((batch_size, T), dtype=torch.long)\n",
    "\n",
    "        # max p(z1:t,all_x|theta)\n",
    "        max_logLL_allz_allx, path[:, -1] = torch.max(log_delta.squeeze(), -1)\n",
    "\n",
    "        for t in range(T-2, -1, -1):\n",
    "            # choose the state of z_t according the state choosed of z_t+1.\n",
    "            path[:, t] = psi[:, t+1].gather(-1,path[:, t+1].view(-1,1)).squeeze()\n",
    "\n",
    "        return max_logLL_allz_allx, path\n",
    "    \n",
    "class MyBert(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, bert, device, freeze_bert=False):\n",
    "        super(MyBert, self).__init__()\n",
    "\n",
    "        self.bert = bert\n",
    "        self.device = device\n",
    "        self.lambda1 = lambda x: x[:, 0]\n",
    "        self.out1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(768, num_cond_conn_op),\n",
    "#             torch.nn.Softmax(dim=-1)\n",
    "        )\n",
    "        self.lambda2 = lambda x: torch.unsqueeze(x, -1)\n",
    "#         self.s1 = torch.nn.Sequential(\n",
    "#             torch.nn.Dropout(0.1),\n",
    "#             torch.nn.Linear(768, 512),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Dropout(0.1),\n",
    "#             torch.nn.Linear(512, 256),\n",
    "#             torch.nn.ReLU(),\n",
    "#         )\n",
    "        self.out2 = torch.nn.Linear(768, num_sel_agg)\n",
    "#         self.softmax1 = torch.nn.Softmax(dim=-1)\n",
    "#         self.s2 = torch.nn.Sequential(\n",
    "#             torch.nn.Dropout(0.1),\n",
    "#             torch.nn.Linear(775, 512),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Dropout(0.1),\n",
    "#             torch.nn.Linear(512, 256),\n",
    "#             torch.nn.ReLU(),\n",
    "#         )\n",
    "        self.out3 = torch.nn.Linear(775, num_cond_op)\n",
    "#         self.softmax2 = torch.nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, query: tuple, input_token_ids_len, input_header_ids_len):\n",
    "        bert_out = self.bert(query['input_token_ids'].to(self.device), query['input_attention_mask'].to(self.device), token_type_ids=query['input_segment_ids'].to(self.device))\n",
    "        logit1 = self.out1(self.lambda1(bert_out[0]))\n",
    "        logit2 = seq_gather((bert_out[0], query['input_header_ids'].to(self.device)))\n",
    "        print(bert_out[0].shape, query['input_header_ids'].shape, logit2.shape)\n",
    "        logit3 = self.lambda2(query['input_header_mask'].to(self.device))\n",
    "        logit4 = logit2 * logit3\n",
    "#         logit5 = logit4.matmul(self.out2.weight.t() * self.mask1)\n",
    "#         if self.out2.bias is not None:\n",
    "#             logit5 += torch.jit._unwrap_optional(self.out2.bias)\n",
    "#         logit5 = self.softmax1(logit5)\n",
    "        logit5 = self.out2(logit4)\n",
    "        logit6 = torch.cat((logit5, logit4), 2)\n",
    "#         logit6 = logit6.matmul(self.out3.weight.t() * self.mask2)\n",
    "#         if self.out3.bias is not None:\n",
    "#             logit6 += torch.jit._unwrap_optional(self.out3.bias)\n",
    "        logit7 = self.out3(logit6)\n",
    "        return logit1, logit5, logit7\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "functioning-helmet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = MyBert(model, device)\n",
    "# m = m.to(device)\n",
    "# count = 0\n",
    "# for a, b ,c in train_loader:\n",
    "#     f, d, e = m(a[0], b, c)\n",
    "#     print(f.shape, d.shape, e.shape)\n",
    "#     break\n",
    "# #     print(f, d, e)\n",
    "#     print(f.shape, d.shape, e.shape)\n",
    "#     breakscheduler = optimizer.lr_scheduler.CosineAnnealingWarmRestarts(optim,T_0=5,T_mult=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "postal-dominican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranger optimizer loaded. \n",
      "Gradient Centralization usage = True\n",
      "GC applied to both conv and fc layers\n",
      "MyBert(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (out1): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=3, bias=True)\n",
      "  )\n",
      "  (out2): Linear(in_features=768, out_features=7, bias=True)\n",
      "  (out3): Linear(in_features=775, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def outputs_to_sqls(preds_cond_conn_op, preds_sel_agg, preds_cond_op, header_lens, label_encoder):\n",
    "    \"\"\"\n",
    "    Generate sqls from model outputs\n",
    "    \"\"\"\n",
    "    preds_cond_conn_op = torch.softmax(preds_cond_conn_op, axis=-1)\n",
    "    preds_sel_agg = torch.softmax(preds_sel_agg, axis=-1)\n",
    "    preds_cond_op = torch.softmax(preds_cond_op, axis=-1)\n",
    "    preds_cond_conn_op = torch.argmax(preds_cond_conn_op, axis=-1)\n",
    "    preds_cond_op = torch.argmax(preds_cond_op, axis=-1)\n",
    "\n",
    "    sqls = []\n",
    "    \n",
    "    for cond_conn_op, sel_agg, cond_op, header_len in zip(preds_cond_conn_op, \n",
    "                                                          preds_sel_agg, \n",
    "                                                          preds_cond_op, \n",
    "                                                          header_lens):\n",
    "        sel_agg = sel_agg[:header_len]\n",
    "        # force to select at least one column for agg\n",
    "        t = sel_agg[:, :-1].max()\n",
    "        one = torch.ones_like(sel_agg)\n",
    "        sel_agg =torch.where(sel_agg == t, one, sel_agg)\n",
    "        sel_agg = torch.argmax(sel_agg, axis=-1)\n",
    "        sql = label_encoder.decode(cond_conn_op, sel_agg, cond_op)\n",
    "        sql['conds'] = [cond for cond in sql['conds'] if cond[0] < header_len]\n",
    "        sel = []\n",
    "        agg = []\n",
    "        for col_id, agg_op in zip(sql['sel'], sql['agg']):\n",
    "            if col_id < header_len:\n",
    "                sel.append(col_id)\n",
    "                agg.append(agg_op)\n",
    "                \n",
    "        sql['sel'] = sel\n",
    "        sql['agg'] = agg\n",
    "        sqls.append(sql)\n",
    "    return sqls\n",
    "\n",
    "from torch.utils import tensorboard\n",
    "# from transformers import get_linear_schedule_with_warmup\n",
    "# from torch_optimizer import RAdam\n",
    "\n",
    "epoch = 10\n",
    "total_steps = len(train_loader) * epoch\n",
    "\n",
    "# optim = RAdam(model.parameters(), lr=5e-5, eps=1e-07)\n",
    "\n",
    "# scheduler = get_linear_schedule_with_warmup(optim,\n",
    "#                                             num_warmup_steps = 0, \n",
    "#                                             num_training_steps = total_steps)\n",
    "\n",
    "objtv1 = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "objtv2 = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "objtv3 = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "step = 0\n",
    "\n",
    "exp_path = r'./model_save3'\n",
    "# Create experiment folder.\n",
    "exp_path = os.path.join(exp_path, r'test')\n",
    "\n",
    "if not os.path.exists(exp_path):\n",
    "    os.makedirs(exp_path)\n",
    "\n",
    "# Create logger and log folder.\n",
    "writer = tensorboard.SummaryWriter(\n",
    "    os.path.join('tens')\n",
    ")\n",
    "\n",
    "# Log average loss.\n",
    "total_loss = 0.0\n",
    "pre_total_loss = 0.0\n",
    "total_cond_op_loss = 0.0\n",
    "pre_cond_op_loss = 0.0\n",
    "total_sel_agg_loss = 0.0\n",
    "pre_sel_agg_loss = 0.0\n",
    "total_cond_conn_op_loss = 0.0\n",
    "pre_cond_conn_op_loss = 0.0\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith('pooler'):\n",
    "        param.requires_grad_(False)\n",
    "    else:\n",
    "        continue\n",
    "                    \n",
    "bert_model = MyBert(model, device).to(device)\n",
    "\n",
    "import torch.optim as optimizer\n",
    "from ranger import Ranger\n",
    "optim = Ranger(bert_model.parameters(), lr=2e-5, eps=1e-07)\n",
    "scheduler = optimizer.lr_scheduler.CosineAnnealingWarmRestarts(optim,T_0=5,T_mult=1)\n",
    "# optim = RAdam(bert_model.parameters(), lr=5e-5, eps=1e-07)\n",
    "print(bert_model)\n",
    "count0 = 0\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "count0 = sum(p.numel() for n, p in bert_model.named_parameters() if n.startswith('out1'))\n",
    "count1 = sum(p.numel() for n, p in bert_model.named_parameters() if n.startswith('out2'))\n",
    "count2 = sum(p.numel() for n, p in bert_model.named_parameters() if n.startswith('out3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "clean-heart",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.000000 , total_cond_op_loss: 0.000000, total_sel_agg_loss: 0.000000, total_cond_conn_op_loss: 0.000000:   0%|          | 0/2596 [00:00<?, ?it/s]/home/jasonchang/Ranger-Deep-Learning-Optimizer/ranger/ranger.py:138: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
      "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
      "epoch: 0, loss: 0.000000 , total_cond_op_loss: 0.000000, total_sel_agg_loss: 0.000000, total_cond_conn_op_loss: 0.000000:   0%|          | 1/2596 [00:00<21:37,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 107, 768]) torch.Size([16, 11]) torch.Size([16, 11, 768])\n",
      "tensor([[-0.3931,  0.2411,  0.1360,  ...,  0.2184,  0.6407, -0.3637],\n",
      "        [-0.3548,  0.2955,  0.0955,  ...,  0.2683,  0.6579, -0.3207],\n",
      "        [-0.3475,  0.3640,  0.1351,  ...,  0.2303,  0.6322, -0.3166],\n",
      "        ...,\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>) tensor([ 6,  6,  6,  1,  1,  6,  6,  6,  6,  6,  6,  6,  6,  0,  6,  6,  6,  6,\n",
      "         6,  6,  6, -1,  0,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1,  6,  6,  6,\n",
      "         0,  6,  6,  6,  6, -1, -1, -1,  6,  0,  6,  6,  6,  6, -1, -1, -1, -1,\n",
      "        -1,  6,  6,  6,  0,  6,  6,  6,  6,  6, -1, -1,  0,  6,  6,  6,  6,  6,\n",
      "         6,  6, -1, -1, -1,  6,  6,  6,  6,  0,  6, -1, -1, -1, -1, -1,  0,  6,\n",
      "         6,  6,  6,  6, -1, -1, -1, -1, -1,  6,  6,  6,  6,  6,  0, -1, -1, -1,\n",
      "        -1, -1,  6,  0,  6,  6,  6,  6,  6, -1, -1, -1, -1,  0,  0,  6,  6,  6,\n",
      "         6,  6,  6, -1, -1, -1,  6,  6,  0,  6,  6,  6,  6,  6,  6, -1, -1,  0,\n",
      "         6,  6,  6,  6,  6,  6, -1, -1, -1, -1,  6,  6,  6,  6,  2,  6,  6, -1,\n",
      "        -1, -1, -1,  6,  0,  0,  6, -1, -1, -1, -1, -1, -1, -1],\n",
      "       device='cuda:0') torch.Size([176, 7]) torch.Size([176])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 5.109733 , total_cond_op_loss: 1.440210, total_sel_agg_loss: 2.482712, total_cond_conn_op_loss: 1.186810:   0%|          | 2/2596 [00:00<13:52,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 134, 768]) torch.Size([16, 17]) torch.Size([16, 17, 768])\n",
      "tensor([[-0.2265,  0.1474, -0.0339,  ...,  0.4800,  0.5868, -0.3346],\n",
      "        [-0.3172,  0.1562, -0.1216,  ...,  0.4475,  0.6033, -0.3483],\n",
      "        [-0.2902,  0.2219, -0.0429,  ...,  0.5516,  0.5488, -0.2842],\n",
      "        ...,\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>) tensor([ 6,  6,  0,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6, -1, -1,  6,\n",
      "         0,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,\n",
      "         6,  6,  6,  6,  0,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  0, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,  0,\n",
      "         6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  6,  0,  6,  6,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  0,  6,  6, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  0,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  0,  6,  6,  0, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  0,  6, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,  6,  0,  0, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,  6,  6,  6,  6,  6,  6,  0,  6,\n",
      "         6,  6,  6,  6, -1, -1,  0,  6,  6,  6,  6,  6,  6,  6,  6, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1,  6,  6,  6,  6,  6,  6,  0,  6,  6,  6,  6,  6,  6,\n",
      "         6, -1, -1, -1,  6,  6,  0,  0,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1,  4,  6,  6,  6,  6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1], device='cuda:0') torch.Size([272, 7]) torch.Size([272])\n",
      "torch.Size([16, 142, 768]) torch.Size([16, 17]) torch.Size([16, 17, 768])\n",
      "tensor([[-0.1782,  0.0780, -0.2841,  ...,  0.3177,  0.6061, -0.2995],\n",
      "        [-0.1587,  0.3283, -0.0512,  ...,  0.4474,  0.6160, -0.4640],\n",
      "        [-0.2891,  0.1491, -0.1042,  ...,  0.4021,  0.5526, -0.4001],\n",
      "        ...,\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>) tensor([ 6,  6,  6,  6,  0,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,\n",
      "         0,  6,  6,  6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1,  6,  0,\n",
      "         6,  6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  1,\n",
      "         6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,  0,\n",
      "         0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  0,  0,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  0,  0,  6, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,  6,  6,  6,  0,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6, -1,  6,  0,  6,  6,  6, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  0,  6,  6, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,  0,  6,  6,  6, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1,  6,  6,  0,  6, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1,  6,  6,  0,  6,  6,  6,  6,  6,  6, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1,  6,  6,  0,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1,  0,  6,  6,  6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1,  6,  6,  0,  6,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1], device='cuda:0') torch.Size([272, 7]) torch.Size([272])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 5.079767 , total_cond_op_loss: 1.474504, total_sel_agg_loss: 2.489885, total_cond_conn_op_loss: 1.115377:   0%|          | 4/2596 [00:01<09:40,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 149, 768]) torch.Size([16, 15]) torch.Size([16, 15, 768])\n",
      "tensor([[-0.2944,  0.1282, -0.0530,  ...,  0.4888,  0.5356, -0.3765],\n",
      "        [-0.3912,  0.1996, -0.0306,  ...,  0.4627,  0.5796, -0.3210],\n",
      "        [-0.3071,  0.1492,  0.1065,  ...,  0.6080,  0.5558, -0.2941],\n",
      "        ...,\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>) tensor([ 6,  6,  0,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6, -1, -1,  0,  6,  6,\n",
      "         6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  6, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,  0,  6, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1,  6,  6,  6,  6,  6,  6,  0,  6, -1, -1, -1, -1,\n",
      "        -1, -1, -1,  6,  6,  6,  6,  6,  6,  0,  6,  6,  6,  6,  6,  6,  6, -1,\n",
      "         6,  6,  6,  0,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  0,  6,  6,\n",
      "         6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,  6,  6,  0,\n",
      "         6, -1, -1, -1, -1, -1, -1, -1, -1,  6,  0,  6,  6,  6,  6, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1,  6,  6,  6,  0,  6,  6, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1,  6,  6,  0,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         6,  0,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  0,\n",
      "         6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1,  0,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  0,  6,  6,  6, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1], device='cuda:0') torch.Size([240, 7]) torch.Size([240])\n",
      "torch.Size([16, 118, 768]) torch.Size([16, 15]) torch.Size([16, 15, 768])\n",
      "tensor([[-0.0157, -0.1302,  0.0106,  ...,  0.5550,  0.5276, -0.4540],\n",
      "        [ 0.3096, -0.0511, -0.0126,  ...,  0.4194,  0.7331, -0.3669],\n",
      "        [-0.1252, -0.0031, -0.0350,  ...,  0.4920,  0.6401, -0.5589],\n",
      "        ...,\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>) tensor([ 6,  6,  6,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,\n",
      "         6,  6,  6,  0,  6,  6,  6,  6,  6,  6,  6,  6,  0,  6,  6,  6,  6, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  0,  6,  6,  6,  6, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1,  6,  6,  6,  6,  6,  6,  6,  0, -1, -1, -1, -1,\n",
      "        -1, -1, -1,  6,  6,  6,  6,  6,  0,  6, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         0,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  0,\n",
      "         6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1,  6,  4,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6, -1, -1,  6,  6,  6,  0, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1,  6,  6,  6,  6,  6,  0, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1,  6,  6,  6,  6,  6,  6,  6,  6,  6,  2, -1, -1, -1, -1, -1,\n",
      "         6,  0,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  0,\n",
      "         6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,  0,  6,  6,\n",
      "         6,  6, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,  6,  6,  6,  6,  0,  6,\n",
      "         6, -1, -1, -1, -1, -1], device='cuda:0') torch.Size([240, 7]) torch.Size([240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 5.127246 , total_cond_op_loss: 1.472592, total_sel_agg_loss: 2.507797, total_cond_conn_op_loss: 1.146857:   0%|          | 6/2596 [00:01<07:49,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 118, 768]) torch.Size([16, 18]) torch.Size([16, 18, 768])\n",
      "tensor([[-0.0149,  0.2022, -0.0910,  ...,  0.5936,  0.1069, -0.2719],\n",
      "        [-0.2915,  0.1463,  0.2892,  ...,  0.4457,  0.5426, -0.2984],\n",
      "        [-0.2869,  0.1844,  0.2081,  ...,  0.5515,  0.5283, -0.3973],\n",
      "        ...,\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>) tensor([ 6,  6,  6,  0,  6,  6,  6,  6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1,\n",
      "         6,  6,  6,  1,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         6,  0,  6,  6,  6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         6,  6,  0,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         6,  0,  6,  6,  0,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         6,  0,  6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         6,  6,  6,  0,  6,  6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         6,  6,  6,  6,  6,  0,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         0,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         6,  6,  6,  0,  6,  6,  0,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         6,  6,  0,  6,  6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         0,  0,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6, -1, -1, -1,\n",
      "         0,  0,  6,  6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         6,  6,  6,  6,  0,  0,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         6,  0,  6,  6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  3, -1, -1, -1, -1, -1, -1, -1, -1],\n",
      "       device='cuda:0') torch.Size([288, 7]) torch.Size([288])\n",
      "torch.Size([16, 129, 768]) torch.Size([16, 16]) torch.Size([16, 16, 768])\n",
      "tensor([[-0.2913,  0.0663, -0.0078,  ...,  0.1577,  0.4876, -0.0876],\n",
      "        [-0.4167,  0.1027, -0.0408,  ...,  0.2633,  0.4466, -0.0871],\n",
      "        [-0.4226,  0.1394, -0.0688,  ...,  0.2850,  0.6641, -0.1940],\n",
      "        ...,\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>) tensor([ 6,  6,  6,  6,  6,  6,  6,  0,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  0,  6,  6,  6,  6,  6, -1, -1, -1, -1, -1,  6,  6,  6,  6,\n",
      "         6,  6,  5,  6,  6,  6,  6,  6, -1, -1, -1, -1,  6,  6,  4,  6,  6, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,  6,  6,  0, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,  6,  0,  6, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1,  6,  0,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1,  4,  6,  6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1,  6,  6,  6,  0,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         6,  6,  6,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  0,\n",
      "         6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  4,  6,  6,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  0,  6,  0,  6,  6, -1, -1, -1,  6,  6,  6,  6,  0, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,  0,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6, -1, -1, -1, -1,  6,  6,  6,  6,  6,  2,  6,  6, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1], device='cuda:0') torch.Size([256, 7]) torch.Size([256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 5.132891 , total_cond_op_loss: 1.482506, total_sel_agg_loss: 2.506215, total_cond_conn_op_loss: 1.144171:   0%|          | 8/2596 [00:01<07:11,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 127, 768]) torch.Size([16, 15]) torch.Size([16, 15, 768])\n",
      "tensor([[-0.3191,  0.2375,  0.3938,  ...,  0.0738,  0.5761, -0.2678],\n",
      "        [-0.2719,  0.3884,  0.2436,  ...,  0.1708,  0.3487, -0.2051],\n",
      "        [-0.3803,  0.2773,  0.3230,  ...,  0.0899,  0.5815, -0.3415],\n",
      "        ...,\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>) tensor([ 6,  6,  0,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6, -1,  6,  0,  6,\n",
      "         0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6, -1, -1, -1, -1, -1,  6,  0,  6,  6,  6, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1,  0,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6, -1, -1,  6,  6,  6,  0,  6,  6,  6,  6,  6,  6,  6, -1, -1, -1, -1,\n",
      "         0,  6,  6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  0,\n",
      "         6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  3,  6, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  0,  0,  6, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1,  6,  6,  6,  0,  6,  6,  6, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1,  0,  0,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  0,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,\n",
      "         0,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  0,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6, -1, -1, -1, -1, -1,  0,  6,  6, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1], device='cuda:0') torch.Size([240, 7]) torch.Size([240])\n",
      "torch.Size([16, 154, 768]) torch.Size([16, 15]) torch.Size([16, 15, 768])\n",
      "tensor([[-0.2434,  0.1742,  0.0776,  ...,  0.3823,  0.7806, -0.3084],\n",
      "        [-0.4369,  0.2266, -0.1570,  ...,  0.3207,  0.6994, -0.5479],\n",
      "        [-0.2259,  0.1844, -0.1916,  ...,  0.4436,  0.6266, -0.3968],\n",
      "        ...,\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>) tensor([ 6,  6,  6,  6,  0,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,\n",
      "         6,  0,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  0, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1,  4,  6,  6,  6, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1,  6,  0,  6,  6,  0,  6, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1,  6,  6,  1,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         6,  0,  6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1,  4,  6,  6,\n",
      "         6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  0,  6,  6,  6,\n",
      "         0, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,  6,  6,  6,  0,  6, -1,\n",
      "        -1, -1, -1, -1, -1, -1,  6,  6,  5,  6,  6,  6,  6, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1,  6,  0,  6,  6,  6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1,\n",
      "         0,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,\n",
      "         6,  6,  0,  6,  6,  6,  6,  6,  6,  6,  6, -1,  6,  6,  6,  6,  6,  6,\n",
      "         0,  6,  6,  6,  6,  6,  6, -1, -1,  6,  6,  6,  6,  6,  0, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1], device='cuda:0') torch.Size([240, 7]) torch.Size([240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 5.114412 , total_cond_op_loss: 1.483729, total_sel_agg_loss: 2.497551, total_cond_conn_op_loss: 1.133131:   0%|          | 10/2596 [00:02<07:59,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 184, 768]) torch.Size([16, 16]) torch.Size([16, 16, 768])\n",
      "tensor([[-0.2467,  0.2871, -0.1350,  ...,  0.4428,  0.4967, -0.6995],\n",
      "        [-0.3382,  0.3624,  0.1507,  ...,  0.4883,  0.5129, -0.6489],\n",
      "        [-0.3430,  0.2040, -0.1151,  ...,  0.3999,  0.8116, -0.6625],\n",
      "        ...,\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>) tensor([ 6,  6,  0,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  0,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6, -1, -1,  6,  0,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1,  6,  4,  6,  6,  6, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  0,  6,  6,  6, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1,  6,  0,  6,  6,  6, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1,  6,  6,  6,  6,  6,  6,  0, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1,  6,  6,  6,  6,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1,  6,  6,  6,  6,  0,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  0,  6,  6,  6,  0,  6,  6,  6,  6,  6,  6,  6,  6, -1, -1,  6,  6,\n",
      "         6,  6,  6,  0,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1,  6,  6,  6,  0,\n",
      "         0,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,  6,  6,  0,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  0,  6,  6,  6,  6,  6,  6,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,  6,  6,  6,  0,  6, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1,  6,  6,  0,  0,  6,  6,  6, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1], device='cuda:0') torch.Size([256, 7]) torch.Size([256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch: 0, loss: 5.114412 , total_cond_op_loss: 1.483729, total_sel_agg_loss: 2.497551, total_cond_conn_op_loss: 1.133131:   0%|          | 10/2596 [00:02<09:47,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 195, 768]) torch.Size([16, 22]) torch.Size([16, 22, 768])\n",
      "tensor([[-0.3132,  0.1609, -0.0429,  ...,  0.2878,  0.4172, -0.0838],\n",
      "        [-0.3129,  0.1950, -0.0208,  ...,  0.2255,  0.5601, -0.2037],\n",
      "        [-0.2782,  0.1488,  0.0218,  ...,  0.1342,  0.5003, -0.1202],\n",
      "        ...,\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263],\n",
      "        [ 0.0235,  0.0179, -0.0144,  ...,  0.0340,  0.0286,  0.0263]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>) tensor([ 6,  4,  6,  6,  6,  6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1,  0,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,  6,  6,  6,  0,  6,  6,  6,\n",
      "         6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  6,  6,  6,  6,  6,\n",
      "         6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1,  0,  6,  6,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1,  6,  6,  6,  6,  0,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6, -1, -1, -1, -1, -1, -1, -1, -1,  6,  6,  6,  0,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  0,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  0,  6,  6,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         6,  0,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1,  6,  1,  6,  6,  6,  6,  6,  6,  6,  6, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1,  0,  6,  6,  6,  6,  6,  6,  6, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  0,  6,  6,  6, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  0,\n",
      "         6,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1,  6,  6,  6,  6,  0,  6,  6,  6,  6, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1,  0,  6,  6,  6,  6,  6,  6,  6,  6,  6, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], device='cuda:0') torch.Size([352, 7]) torch.Size([352])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-ec09d5d269ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Backward pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         torch.nn.utils.clip_grad_norm_(\n",
      "\u001b[0;32m~/anaconda3/envs/bert/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bert/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for cur_epoch in range(epoch):\n",
    "    tqdm_dldr = tqdm(\n",
    "        train_loader,\n",
    "        desc=f'epoch: {cur_epoch}, loss: {pre_total_loss:.6f} , total_cond_op_loss: {pre_cond_op_loss:.6f}, total_sel_agg_loss: {pre_sel_agg_loss:.6f}, total_cond_conn_op_loss: {pre_cond_conn_op_loss:.6f}'\n",
    "    )\n",
    "    bert_model.train()\n",
    "    for i, batch in enumerate(tqdm_dldr):\n",
    "        b, len1, len2, _= batch\n",
    "        x, y = b\n",
    "        \n",
    "        # Clean up gradient.\n",
    "        optim.zero_grad()\n",
    "        # Forward pass.\n",
    "        logits = bert_model(\n",
    "            x,\n",
    "            len1,\n",
    "            len2,\n",
    "        )\n",
    "        \n",
    "        out_cond_conn_op, out_sel_agg, out_cond_op = logits\n",
    "\n",
    "        y['output_cond_op'] = y['output_cond_op'].to(device, dtype=torch.int64)\n",
    "        y['output_sel_agg'] = y['output_sel_agg'].to(device, dtype=torch.int64)\n",
    "        y['output_cond_conn_op'] = y['output_cond_conn_op'].to(device, dtype=torch.int64)\n",
    "        \n",
    "        # Calculate loss.\n",
    "        cond_op_loss = objtv1(\n",
    "            out_cond_op.reshape(out_cond_op.shape[0] * out_cond_op.shape[1], -1),\n",
    "            y['output_cond_op'].reshape(-1),\n",
    "        )\n",
    "        print(\n",
    "            out_sel_agg.reshape(out_sel_agg.shape[0] * out_sel_agg.shape[1], -1),\n",
    "            y['output_sel_agg'].reshape(-1),\n",
    "            out_sel_agg.reshape(out_sel_agg.shape[0] * out_sel_agg.shape[1], -1).shape,\n",
    "            y['output_sel_agg'].reshape(-1).shape,\n",
    "        )\n",
    "        \n",
    "        sel_agg_loss = objtv2(\n",
    "            out_sel_agg.reshape(out_sel_agg.shape[0] * out_sel_agg.shape[1], -1),\n",
    "            y['output_sel_agg'].reshape(-1),\n",
    "        )\n",
    "\n",
    "        cond_conn_op_loss = objtv3(\n",
    "            out_cond_conn_op,\n",
    "            y['output_cond_conn_op'].reshape(-1),\n",
    "        )\n",
    "\n",
    "        loss = cond_op_loss + sel_agg_loss + cond_conn_op_loss\n",
    "        \n",
    "        # Accumulate loss.\n",
    "        total_loss += loss.item()\n",
    "        total_cond_op_loss += cond_op_loss.item()\n",
    "        total_sel_agg_loss += sel_agg_loss.item()\n",
    "        total_cond_conn_op_loss += cond_conn_op_loss.item()\n",
    "\n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=bert_model.parameters(),\n",
    "            max_norm=1.0,\n",
    "        )\n",
    "\n",
    "\n",
    "        # Gradient descent.\n",
    "        scheduler.step(cur_epoch + i / 5)\n",
    "        optim.step()\n",
    "\n",
    "        # Log average loss on CLI.\n",
    "        tqdm_dldr.set_description(\n",
    "            desc=f'epoch: {cur_epoch}, loss: {pre_total_loss:.6f} , total_cond_op_loss: {pre_cond_op_loss:.6f}, total_sel_agg_loss: {pre_sel_agg_loss:.6f}, total_cond_conn_op_loss: {pre_cond_conn_op_loss:.6f}'\n",
    "        )\n",
    "        step += 1\n",
    "#        # Log average loss on tensorboard.\n",
    "        if step%500 == 0:\n",
    "            writer.add_scalar('Train/Loss', total_loss/(i+1), step)\n",
    "            writer.flush()\n",
    "        pre_total_loss = total_loss / (i+1)\n",
    "        pre_cond_op_loss = total_cond_op_loss / (i+1)\n",
    "        pre_sel_agg_loss = total_sel_agg_loss / (i+1)\n",
    "        pre_cond_conn_op_loss = total_cond_conn_op_loss / (i+1)\n",
    "\n",
    "    # Clean up average loss.\n",
    "    total_loss = 0.0\n",
    "    total_cond_op_loss = 0.0\n",
    "    total_sel_agg_loss = 0.0\n",
    "    total_cond_conn_op_loss = 0.0\n",
    "    tqdm_dldr.set_description(\n",
    "        desc=f'epoch: {cur_epoch}, loss: {pre_total_loss:.6f} , total_cond_op_loss: {pre_cond_op_loss:.6f}, total_sel_agg_loss: {pre_sel_agg_loss:.6f}, total_cond_conn_op_loss: {pre_cond_conn_op_loss:.6f}'\n",
    "    )\n",
    "    \n",
    "    #eval\n",
    "    bert_model.eval()\n",
    "    pred_sqls = []\n",
    "    true_sqls = []\n",
    "    for b, len1, len2, true_sqls_list in val_loader:\n",
    "        header_lens = torch.sum(b[0]['input_header_mask'], axis=-1)\n",
    "        preds_cond_conn_op, preds_sel_agg, preds_cond_op = bert_model(b[0], len1, len2)\n",
    "        sqls = outputs_to_sqls(preds_cond_conn_op, preds_sel_agg, preds_cond_op, \n",
    "                                   header_lens, label_encoder)\n",
    "        pred_sqls += sqls\n",
    "        true_sqls += [s for s in true_sqls_list]\n",
    "            \n",
    "    conn_correct = 0\n",
    "    agg_correct = 0\n",
    "    conds_correct = 0\n",
    "    conds_col_id_correct = 0\n",
    "    all_correct = 0\n",
    "    num_queries = len(val_loader) * batch_size -4\n",
    "    \n",
    "    for pred_sql, true_sql in zip(pred_sqls, true_sqls):\n",
    "        n_correct = 0\n",
    "        if pred_sql['cond_conn_op'] == true_sql['cond_conn_op']:\n",
    "            conn_correct += 1\n",
    "            n_correct += 1\n",
    "            \n",
    "        pred_aggs = set(zip(pred_sql['sel'], pred_sql['agg']))\n",
    "        true_aggs = set(zip(true_sql['sel'], true_sql['agg']))\n",
    "        if pred_aggs == true_aggs:\n",
    "            agg_correct += 1\n",
    "            n_correct += 1\n",
    "\n",
    "        pred_conds = set([(cond[0], cond[1]) for cond in pred_sql['conds']])\n",
    "        true_conds = set([(cond[0], cond[1]) for cond in true_sql['conds']])\n",
    "\n",
    "        if pred_conds == true_conds:\n",
    "            conds_correct += 1\n",
    "            n_correct += 1\n",
    "   \n",
    "        pred_conds_col_ids = set([cond[0] for cond in pred_sql['conds']])\n",
    "        true_conds_col_ids = set([cond[0] for cond in true_sql['conds']])\n",
    "        if pred_conds_col_ids == true_conds_col_ids:\n",
    "            conds_col_id_correct += 1\n",
    "            \n",
    "        if n_correct == 3:\n",
    "            all_correct += 1\n",
    "\n",
    "    print('conn_acc: {}'.format(conn_correct / num_queries))\n",
    "    print('agg_acc: {}'.format(agg_correct / num_queries))\n",
    "    print('conds_acc: {}'.format(conds_correct / num_queries))\n",
    "    print('conds_col_id_acc: {}'.format(conds_col_id_correct / num_queries))\n",
    "    print('total_acc: {}'.format(all_correct / num_queries))\n",
    "    writer.add_scalar('VAL/Accuracy', all_correct / num_queries, cur_epoch)\n",
    "    writer.flush()\n",
    "    aa = exp_path + str(cur_epoch)\n",
    "    if not os.path.exists(aa):\n",
    "        os.makedirs(aa)\n",
    "\n",
    "# Save last checkpoint.\n",
    "    torch.save(\n",
    "        bert_model.state_dict(),\n",
    "        os.path.join(aa, f'model.pt'),\n",
    "    )\n",
    "\n",
    "# Close logger.\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = MyBert(model, device).to(device)\n",
    "bert_model.load_state_dict(torch.load('./model_save2/test9/model.pt'))\n",
    "bert_model.eval()\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, collate_fn=collate_fn2, shuffle=False,num_workers=10)\n",
    "\n",
    "pred_sqls = []\n",
    "with torch.no_grad():\n",
    "    for b, len1, len2, true_sqls_list in test_loader:\n",
    "        header_lens = torch.sum(b[0]['input_header_mask'], axis=-1)\n",
    "        preds_cond_conn_op, preds_sel_agg, preds_cond_op = bert_model(b[0], len1, len2)\n",
    "        sqls = outputs_to_sqls(preds_cond_conn_op, preds_sel_agg, preds_cond_op, \n",
    "                                   header_lens, label_encoder)\n",
    "        pred_sqls += sqls\n",
    "# print(pred_sqls)\n",
    "task1_output_file = 'task1_final_test1_output.json'\n",
    "with open(task1_output_file, 'w') as f:\n",
    "    for sql in pred_sqls:\n",
    "        json_str = json.dumps(sql, ensure_ascii=False)\n",
    "        f.write(json_str + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_output_file = 'task1_output.json'\n",
    "with open(task1_output_file, 'w') as f:\n",
    "    for sql in pred_sqls:\n",
    "        json_str = json.dumps(sql, ensure_ascii=False)\n",
    "        f.write(json_str + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-triangle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
